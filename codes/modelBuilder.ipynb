{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vOnNDmGNaqmsURsV3InCMFmb_lHL8ttj",
      "authorship_tag": "ABX9TyOz9ihPNBzAlfkhuy7kSUkr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisHVieira/tcc/blob/main/modelBuilder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ7n269ZlVfT",
        "outputId": "2e66620b-1c36-4caf-916b-2692e9d445d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.3.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (23.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.5.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2023.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend\n",
        "from keras.optimizers import Adam, Optimizer\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import GlobalAvgPool1D\n",
        "from livelossplot import PlotLossesKeras\n",
        "from enum import Enum\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score, accuracy_score, hamming_loss\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time, datetime"
      ],
      "metadata": {
        "id": "ZxwoxIofhSVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Architecture(Enum):\n",
        "  VGG16 = 'vgg16'\n",
        "  RESNET50V2 = 'resnet50'\n",
        "  MOBILENETV2 = 'mobilenet'"
      ],
      "metadata": {
        "id": "b0TO9vXZt1Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Datas():\n",
        "\n",
        "  list_generate = []\n",
        "  list_data = []\n",
        "\n",
        "\n",
        "  def __init__(self, target_size = (224, 224),  batch_size = 32) -> None:\n",
        "    self.target_size = target_size\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def data_augumentation(self) -> None:\n",
        "\n",
        "    generate_train = ImageDataGenerator(rotation_range= 7, horizontal_flip=True, shear_range=0.2, height_shift_range=0.07, zoom_range= 0.2, preprocessing_function=preprocess_input)\n",
        "    generate_test = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "    self.list_generate.clear()\n",
        "    self.list_generate.append(generate_train)\n",
        "    self.list_generate.append(generate_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def load_dataSet(self, paths_datas:list) -> None:\n",
        "\n",
        "    generate_train, generate_test = self.list_generate\n",
        "    path_train, path_val, path_test = paths_datas\n",
        "\n",
        "    try:\n",
        "      data_train = generate_train.flow_from_directory( path_train, target_size=self.target_size, batch_size=self.batch_size, shuffle=True)\n",
        "      data_val =  generate_train.flow_from_directory( path_val, target_size=self.target_size,  batch_size=self.batch_size, shuffle=True)\n",
        "      data_test =  generate_test.flow_from_directory( path_test, target_size=self.target_size, class_mode=None, batch_size=1, shuffle=False)\n",
        "\n",
        "      self.list_data.clear()\n",
        "      self.list_data.append(data_train)\n",
        "      self.list_data.append(data_val)\n",
        "      self.list_data.append(data_test)\n",
        "\n",
        "    except NotADirectoryError as not_dir:\n",
        "      print(not_dir)\n"
      ],
      "metadata": {
        "id": "5OvSInztQjAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Builder():\n",
        "\n",
        "  input_shape = (224, 224, 3)\n",
        "  callbacks = []\n",
        "  n_steps = 0\n",
        "  n_val_steps = 0\n",
        "  total_time = 0\n",
        "  model = None\n",
        "  history = None\n",
        "\n",
        "  def __init__(self, data:Datas, architecture:Architecture, n_epochs = 100,  optimizer = Adam(learning_rate=0.0001), fine_tune=0) -> None:\n",
        "    self.batch_size = data.batch_size\n",
        "    self.data_train = data.list_data[0]\n",
        "    self.data_val = data.list_data[1]\n",
        "    self.n_classes = self.data_train.num_classes\n",
        "    self.architecture = Architecture(architecture)\n",
        "    self.n_epochs = n_epochs\n",
        "    self.optimizer = optimizer\n",
        "    self.fine_tune = fine_tune\n",
        "    self.set_callbacks()\n",
        "    self.set_steps()\n",
        "\n",
        "\n",
        "  def set_callbacks(self) -> None:\n",
        "\n",
        "    base_name = 'bestWeights' + str(self.architecture.name)\n",
        "    ext = '.weights.best.hdf5'\n",
        "\n",
        "    name_file = base_name + ext if self.fine_tune == 0 else base_name + '_with_fine_tune' + ext\n",
        "\n",
        "    self.callbacks =  [\n",
        "                        PlotLossesKeras(),\n",
        "                        EarlyStopping(monitor = 'val_loss', patience = 5 ),\n",
        "                        ModelCheckpoint( filepath = name_file, save_best_only=True, save_weights_only=True, verbose=1)\n",
        "                      ]\n",
        "\n",
        "  def set_steps(self) -> None:\n",
        "\n",
        "    self.n_steps = self.data_train.samples // self.batch_size\n",
        "    self.n_val_steps = self.data_val.samples // self.batch_size\n",
        "\n",
        "\n",
        "  def summary_model(self) -> None:\n",
        "\n",
        "    self.model._name = str(self.architecture.name) if self.fine_tune == 0 else str(self.architecture.name) + '_With_Fine_Tune'\n",
        "\n",
        "    self.model.summary( show_trainable=True )\n",
        "\n",
        "\n",
        "  def create_model(self) -> None:\n",
        "\n",
        "      if self.architecture == Architecture.RESNET50V2:\n",
        "        from keras.applications.resnet_v2 import ResNet50V2\n",
        "        model_choose = ResNet50V2(include_top=False, weights='imagenet', input_shape=self.input_shape)\n",
        "\n",
        "      elif self.architecture == Architecture.MOBILENETV2:\n",
        "        from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "        model_choose = MobileNetV2(include_top=False, weights='imagenet', input_shape=self.input_shape)\n",
        "\n",
        "      else:\n",
        "        from keras.applications.vgg16 import VGG16\n",
        "        model_choose = VGG16(include_top=False, weights='imagenet', input_shape=self.input_shape)\n",
        "\n",
        "\n",
        "      if self.fine_tune > 0:\n",
        "        for layer in model_choose.layers[:-self.fine_tune]:\n",
        "                layer.trainable = False\n",
        "      else:\n",
        "        for layer in model_choose.layers:\n",
        "                layer.trainable = True\n",
        "\n",
        "      top_model = model_choose.output\n",
        "      top_model = GlobalAveragePooling2D()(top_model)\n",
        "      top_model = Dense (4096, activation='relu')(top_model)\n",
        "      top_model = Dense(1072, activation='relu')(top_model)\n",
        "      output_layer = Dense(self.n_classes, activation='softmax')(top_model)\n",
        "\n",
        "      self.model = Model(inputs=model_choose.input, outputs=output_layer)\n",
        "\n",
        "      self.model.compile(optimizer=self.optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "      return self.model\n",
        "\n",
        "\n",
        "\n",
        "  def fit_model(self) -> None:\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    self.history = self.model.fit( self.data_train,\n",
        "                          batch_size = self.batch_size,\n",
        "                          epochs = self.n_epochs,\n",
        "                          validation_data = self.data_val,\n",
        "                          steps_per_epoch = self.n_steps,\n",
        "                          validation_steps = self.n_val_steps,\n",
        "                          callbacks = self.callbacks,\n",
        "                          verbose = 1)\n",
        "\n",
        "    end_time = time.time()\n",
        "    self.total_time = int(end_time - start_time)\n"
      ],
      "metadata": {
        "id": "mZejp2tomrNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluator():\n",
        "\n",
        "  y_pred = None\n",
        "\n",
        "  def __init__(self, data:Datas, builder: Builder) -> None:\n",
        "    self.batch_size = data.batch_size\n",
        "    self.data_test = data.list_data[2]\n",
        "    self.architecture = builder.architecture\n",
        "    self.fine_tune = builder.fine_tune\n",
        "    self.callbacks = builder.callbacks\n",
        "    self.n_epochs = builder.n_epochs\n",
        "    self.lr = builder.optimizer.lr\n",
        "    self.total_time = builder.total_time\n",
        "    self.model = builder.model\n",
        "    self.history = builder.history\n",
        "\n",
        "\n",
        "\n",
        "  def about(self) -> None:\n",
        "\n",
        "    seconds  = self.total_time\n",
        "    hour = seconds // 3600\n",
        "    seconds = seconds % 3600\n",
        "    min = seconds // 60\n",
        "    seconds = seconds % 60\n",
        "\n",
        "\n",
        "    lr = float(backend.get_value(self.lr))\n",
        "\n",
        "    print('Last Trainning and evaluate:', datetime.datetime.now().date())\n",
        "    print('Architecture:', self.architecture.name)\n",
        "    print('Batch Size:', self.batch_size)\n",
        "    print('Learnning Rate:', str(lr))\n",
        "    print('Fine Tune: ' + ('unrealized (all layers)' if self.fine_tune == 0 else str(self.fine_tune)))\n",
        "    print('Epochs covered / Epochs total: {:d} / {:d}'.format(len(self.history.history['loss']), self.n_epochs))\n",
        "    print('Time Trainning: {:d}:{:d}:{:d}'.format(hour, min, seconds))\n",
        "\n",
        "  def report(self) -> None:\n",
        "\n",
        "    self.model.load_weights(self.callbacks[2].filepath)\n",
        "\n",
        "    y_pred = self.model.predict(self.data_test, batch_size=self.batch_size, verbose=1)\n",
        "    self.y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    report = classification_report(self.data_test.classes, self.y_pred)\n",
        "\n",
        "    print(report)\n",
        "\n",
        "\n",
        "  def metrics(self) -> None:\n",
        "\n",
        "    print('Recall: %.3f' % recall_score(self.data_test.classes, self.y_pred, average='weighted'))\n",
        "    print('Precision: %.3f' % precision_score(self.data_test.classes, self.y_pred, average='weighted'))\n",
        "    print('Accuracy: %.3f' % accuracy_score(self.data_test.classes, self.y_pred))\n",
        "    print('Loss %.3f' % hamming_loss(self.data_test.classes, self.y_pred))\n",
        "\n",
        "\n",
        "  def confusion_matrix(self) -> None:\n",
        "\n",
        "\n",
        "    y_true = self.data_test.classes\n",
        "    class_names = self.data_test.class_indices.keys()\n",
        "\n",
        "\n",
        "    cm_support = confusion_matrix( y_true, self.y_pred)\n",
        "\n",
        "    #Calculo da precisao\n",
        "    cm_precision = cm_support.astype('float') / cm_support.sum(axis=0)[:, np.newaxis]\n",
        "\n",
        "    precision = ((np.asarray(cm_precision)).reshape(5,5))\n",
        "    support = ((np.asarray(cm_support)).reshape(5,5))\n",
        "\n",
        "    labels = (np.asarray([\"{:d} \\n  {:.2f}\".format(sup,pre)\n",
        "                      for pre, sup in zip(precision.flatten(),\n",
        "                                               support.flatten())])).reshape(5,5)\n",
        "\n",
        "    fig, (ax) = plt.subplots(1, figsize=(10, 10))\n",
        "\n",
        "    sns.heatmap(\n",
        "        cm_precision,\n",
        "        annot=labels,\n",
        "        square=True,\n",
        "        xticklabels=class_names,\n",
        "        yticklabels=class_names,\n",
        "        fmt='',\n",
        "        cmap=plt.cm.Blues,\n",
        "        cbar=False,\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    fine_tune_bool = '' if self.fine_tune == 0 else ' c/ Ajuste Fino'\n",
        "    title = \"Matriz de Confusão \" + self.architecture.name + fine_tune_bool\n",
        "\n",
        "    ax.set_title(title, fontsize=16)\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
        "    ax.set_ylabel('Classe Verdadeira', fontsize=12)\n",
        "    ax.set_xlabel('Classe Prevista', fontsize=12)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kGYTkMnymr-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}